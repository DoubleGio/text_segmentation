{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, shutil, re, tarfile\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_DIR = '../GraphSeg/data/input_orig'\n",
    "INPUT_DIR = '../GraphSeg/data/input'\n",
    "OUTPUT_DIR = '../GraphSeg/data/output'\n",
    "SEG_EN = '../GraphSeg/binary/graphseg_en.jar'\n",
    "SEG_NL = '../GraphSeg/binary/graphseg_nl.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(location: str, n=5, wiki=False):\n",
    "    \"\"\"\n",
    "    Copy n files from location to input_orig directory.\n",
    "    Removes wiki-header if wiki=True.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(location):\n",
    "        for file in files:\n",
    "            if count >= n:\n",
    "                return\n",
    "            if not os.path.exists(os.path.join(ORIG_DIR, file)):\n",
    "                shutil.copy(os.path.join(root, file), ORIG_DIR)\n",
    "                if wiki:\n",
    "                    with open(os.path.join(ORIG_DIR, file), 'r+') as orig:\n",
    "                        data = orig.read()\n",
    "                        orig.seek(0)\n",
    "                        orig.write(re.sub(r'^(?:(<doc)|(\\n<\\/doc)).*\\n', '', data, flags=re.MULTILINE))\n",
    "                        orig.truncate()\n",
    "            count += 1\n",
    "\n",
    "def clean_data():\n",
    "    \"\"\"\n",
    "    Clean up docs, place them in input directory.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(ORIG_DIR):\n",
    "        for file in files:\n",
    "            with open(os.path.join(root, file), 'r') as f:\n",
    "                doc = f.read()\n",
    "            with open(os.path.join(INPUT_DIR, file), 'w') as f2:\n",
    "                f2.write(re.sub(r'^=+.*\\n+', '', doc, flags=re.MULTILINE))\n",
    "\n",
    "def reset_data_folder():\n",
    "    \"\"\"\n",
    "    Reset the input_orig, input and output directories.\n",
    "    \"\"\"\n",
    "    for folder in [ORIG_DIR, INPUT_DIR, OUTPUT_DIR]:\n",
    "        for file in os.listdir(folder):\n",
    "            path = os.path.join(folder, file)\n",
    "            try:\n",
    "                if os.path.isfile(path) or os.path.islink(path):\n",
    "                    os.unlink(path)\n",
    "                elif os.path.isdir(path):\n",
    "                    shutil.rmtree(path)\n",
    "            except OSError as e:\n",
    "                print(f'Failed to delete {path}. Reason: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENWiki tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_data_folder()\n",
    "copy_data('../ENWiki/data', n=5)\n",
    "clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the jar (and ðŸ™)\n",
    "output = subprocess.run(['java', '-jar', SEG_EN, INPUT_DIR, OUTPUT_DIR, '0.25', '2'], capture_output=True, text=True)\n",
    "print(output.stdout)\n",
    "# TODO: Possibly change graphseg_en.jar to include the new quiet option so live-printing works nicer\n",
    "# with subprocess.Popen(['java', '-jar', SEG_EN, INPUT_DIR, OUTPUT_DIR, '0.25', '2'], stdout=subprocess.PIPE, universal_newlines=True) as popen:\n",
    "#     for line in popen.stdout:\n",
    "#         print(line)\n",
    "# if popen.returncode != 0:\n",
    "#     raise subprocess.CalledProcessError(popen.returncode, popen.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLWiki tests\n",
    "Dutch alternatives:\n",
    "* https://github.com/dcferreira/multilingual-joint-embeddings for word embeddings (it is based on what's used by the English version)\n",
    "* http://crr.ugent.be/programs-data/subtitle-frequencies/subtlex-nl/downloading for word frequencies\n",
    "* `nltk.corpus.stopwords.words('dutch')` for stopwords\n",
    "\n",
    "To compile the .jar:\n",
    "```\n",
    "cd text_segmentation/GraphSeg/source/\n",
    "mvn package\n",
    "```\n",
    "File is found in /binary folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating replacements for the English resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract correct word embeddings\n",
    "tar = tarfile.open('../GraphSeg/backups/multilingual_embeddings.tar.gz')\n",
    "names = tar.getnames()\n",
    "nl_file = [tar.getmember(name=n) for n in names if n.endswith('.nl')]\n",
    "tar.extractall(path='../GraphSeg/source/res', members=nl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform word frequency csv into correct .txt format\n",
    "df = pd.read_csv('../GraphSeg/backups/SUBTLEX-NL.cd-above2.txt', sep='\\t', header=0)\n",
    "out_str = df.iloc[:, :2].to_string(header=False, index=False, justify='left')\n",
    "with open('../GraphSeg/source/res/freqs.txt', 'w') as out:\n",
    "    spaces_replaced = re.sub(r'[ \\t]+', ' ', out_str, flags=re.MULTILINE)   # Replace multi-spaces/tabs with single space\n",
    "    out.write(re.sub(r'^[ ]', '', spaces_replaced, flags=re.MULTILINE))     # Remove space at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stopwords from nltk and put them into a .txt file\n",
    "nl_sw = stopwords.words('dutch')\n",
    "with open('../GraphSeg/source/res/stopwords.txt', 'w') as out:\n",
    "    out.write('\\n'.join(nl_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_data_folder()\n",
    "copy_data('../NLWiki/data', wiki=True)\n",
    "clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the jar (and ðŸ™)\n",
    "with subprocess.Popen(['java', '-jar', SEG_NL, INPUT_DIR, OUTPUT_DIR, '0.25', '2', '-q'], stdout=subprocess.PIPE, universal_newlines=True) as popen:\n",
    "    for line in popen.stdout:\n",
    "        print(line)\n",
    "if popen.returncode != 0:\n",
    "    raise subprocess.CalledProcessError(popen.returncode, popen.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f978b396a6de9f6071591ed551517b33307dc604add4bc2313196a31dd808f97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('gio': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
